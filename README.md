This repository contains the lab work for Coursera course on Generative AI with Large Language Models. https://www.coursera.org/learn/generative-ai-with-llms
Week1 Lab1: Dialog summarization using Gen-AI. Learn and experiment with zero shot, one shot and few shot inferences. Also learn to tune model associated configuration parameters at inference and see how results are getting influenced.
Week2-Lab: Use Parameter efficient fine tuning (PEFT) and full fine tuning on an existing LLM from Hugging Face, Flan-T5 model. Explore methods such as Low Rank Adaptation (LoRA) and evaluate the model using various ROUGE metrics.
Week3-Lab:  RLHF: Reinforcement learning with human feedback. Use reinforcement learning with reward model (Meta AI hate speech reward model) to further tune Flan-T5 and generate less toxic summaries. This lab uses Proximal Policy Optimization (PPO) algorithm to fine-tuning and detoxify the model.
